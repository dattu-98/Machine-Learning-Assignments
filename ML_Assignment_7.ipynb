{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5d1db4",
   "metadata": {},
   "source": [
    "**1. What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d1e2e",
   "metadata": {},
   "source": [
    "1. A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results.\n",
    "2. The target function is essentially the formula that an algorithm feeds data to in order to calculate predictions.\n",
    "3. It can be expressed in a simple way with a chess game. The training data will be fed to the algorithm, it gets feed back in each and every step. It will select particular step in order to win the match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778cbfc",
   "metadata": {},
   "source": [
    "**2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa261",
   "metadata": {},
   "source": [
    "Predictive models: These models are all about predicting the future values or else type of class to which it belong. There are different types of algorithms in Machine Learning in which the model works in different way with different accuracy.\n",
    "\n",
    "Desriptive types: These is all about what happened in the past. This will be give insights & value from the data what happened in the past. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a9bb3",
   "metadata": {},
   "source": [
    "**3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b261581",
   "metadata": {},
   "source": [
    "1. Confusion Matrix\n",
    "\n",
    "![](https://miro.medium.com/max/1000/1*fxiTNIgOyvAombPJx5KGeA.png)\n",
    "\n",
    "2. Precision: Precision can be defined as ratio of True positive upon TP & FP\n",
    "3. Recall/ Sensitivity: Sensitivity can be defined as ratio of true positive upon TN & FN\n",
    "4. Specificity: Specificity can be defined as ratio of True Negative upon TN & FP\n",
    "5. F1-Score: F1 score is a weighted average of Precision and Recall, which means there is equal importance given to FP and FN. \n",
    "6. AUC & ROC Curve: AUC or Area Under Curve is used in conjecture with ROC Curve which is Receiver Operating Characteristics Curve. AUC is the area under the ROC Curve. \n",
    "![](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/12/roc-curve-original.png?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1b9af",
   "metadata": {},
   "source": [
    "**4. i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    "    ii. What does it mean to overfit? When is it going to happen?\n",
    "    iii. In the sense of model fitting, explain the bias-variance trade-off.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdec2b",
   "metadata": {},
   "source": [
    "1. Underfitting: A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data.  It usually happens when we have fewer data to build an accurate model and also when we try to build a linear model with fewer non-linear data. This destroys the accuracy of our machine learning model. Underfitting can be simply explained as High bias and low variance \n",
    "\n",
    "2. Overfitting: A statistical model is said to be overfitted when we train it with a lot of data. Then the model does not categorize the data correctly, because of too many details and noise. The causes of overfitting are the non-parametric and non-linear methods. Overfitting can be simply explained as Low bias and High variance.\n",
    "\n",
    "3. Bias-Variance Trade-off: If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if our model has large number of parameters then it’s going to have high variance and low bias. So we need to find the right/good balance without overfitting and underfitting the data. This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time. Total error should be minimum in order to find a better model.\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*9hPX9pAO3jqLrzt0IE3JzA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13e1ad",
   "metadata": {},
   "source": [
    "**5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ee011",
   "metadata": {},
   "source": [
    "Yes. We can increase the efficiency of ML model by\n",
    "1. Adding more data\n",
    "2. Removing outliers & proper data pre processing\n",
    "3. Feature Engineering\n",
    "4. Feature selection\n",
    "5. Ensemble methods\n",
    "6. Tuning of Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c5453",
   "metadata": {},
   "source": [
    "**6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3d11e",
   "metadata": {},
   "source": [
    "There are different methods in order to find the Success of Unsupervised learning models. \n",
    "1. Silhouette Score\n",
    "2. Adjusted Rand Index\n",
    "3. Fowlkes Mallows Score\n",
    "4. Calinski Harabaz Index\n",
    "\n",
    "We can find all the metrics for the models in the sklearn.metrics function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad585bec",
   "metadata": {},
   "source": [
    "**7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8b95e",
   "metadata": {},
   "source": [
    "Yes. It is possible to use classification model for numerical data. It is possible with Decision trees, ensemble techniques. The usage of Decision trees, ensemble technique will be effective as it produces higher accuracy when compared with single algorithm.\n",
    "\n",
    "Yes it is possible to use regressional model for classification data. We can use logistic regression for categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0d200",
   "metadata": {},
   "source": [
    "**8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a441147",
   "metadata": {},
   "source": [
    "The predictive modelling for numerical values of continous data is used with the help of Regression Techniques. With the help of this we will be able to find the future values with the help of models. \n",
    "Below are the few regression modelling techniques for numerical variables\n",
    "1. Linear Regression\n",
    "2. Decision Tree\n",
    "3. Support Vector Regression\n",
    "4. Lasso Regression\n",
    "5. Random Forest\n",
    "\n",
    "The categorical predictive modelling is nothing but prediction the output in the form of classes. There are several algorithms for prediction of output classes. Few of them are:\n",
    "1. Logistic Regression\n",
    "2. Naïve Bayes\n",
    "3. Stochastic Gradient Descent\n",
    "4. K-Nearest Neighbours\n",
    "5. Decision Tree\n",
    "6. Random Forest\n",
    "7. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731853a",
   "metadata": {},
   "source": [
    "**9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:\n",
    "         i. Accurate estimates – 15 cancerous, 75 benign\n",
    "         ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "                Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c3c4b8",
   "metadata": {},
   "source": [
    "1. Models Error Rate: 0.1\n",
    "2. Kappa value: 0.688\n",
    "3. Sensitivity: 0.833\n",
    "4. Precision: 0.681\n",
    "5. F-Measure: 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ebb0c8",
   "metadata": {},
   "source": [
    "**10. Make quick notes on:\n",
    "         1. The process of holding out\n",
    "         2. Cross-validation by tenfold\n",
    "         3. Adjusting the parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae68c94",
   "metadata": {},
   "source": [
    "1. The holding out method for training a machine learning model is the process of splitting the data in different splits and using one split for training the model and other splits for validating and testing the models.\n",
    "\n",
    "2. Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it. 10-fold cross validation would perform the fitting procedure a total of ten times, with each fit being performed on a training set consisting of 90% of the total training set selected at random, with the remaining 10% used as a hold out set for validation. \n",
    "\n",
    "3. Parameters are internal to the model. That is, they are learned or estimated purely from the data during training as the algorithm used tries to learn the mapping between the input features and the labels or targets. The learning algorithm is continuously updating the parameter values as learning progress but hyperparameter values set by the model designer remain unchanged. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ab97c",
   "metadata": {},
   "source": [
    "**11. Define the following terms: \n",
    "         1. Purity vs. Silhouette width\n",
    "         2. Boosting vs. Bagging\n",
    "         3. The eager learner vs. the lazy learner**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36267f3",
   "metadata": {},
   "source": [
    "1.1)  Purity is easy to calculate. When we assign a label to each cluster based on the most frequent class in it. Then the purity becomes the number of correctly matched class and cluster labels divided by the number of total data points.\n",
    "\n",
    "1.2)  Silhouette width is defined as the ratio of average distance of each sample to samples in the same cluster to the smallest distance to samples not in the same cluster.  If silhouette width is close to 1, it means that sample is well clustered.\n",
    "\n",
    "2.1)  Boosting: Boosting is an ensemble modeling technique that attempts to build a strong classifier from the number of weak classifiers. It is done by building a model by using weak models in series. Firstly, a model is built from the training data. Then the second model is built which tries to correct the errors present in the first model. This procedure is continued and models are added until either the complete training data set is predicted correctly or the maximum number of models are added.\n",
    "\n",
    "2.2) Bagging: Bootstrap Aggregating, also knows as bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It decreases the variance and helps to avoid overfitting.\n",
    "\n",
    "3. Eager learning methods construct general, explicit description of the target function based on the provided training examples where as Lazy learning methods simply store the data and generalizing beyond these data is postponed until an explicit request is made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
